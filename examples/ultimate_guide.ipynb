{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5a5aaf8",
   "metadata": {},
   "source": [
    "# The Ultimate Guide to ml-assert\n",
    "This notebook provides a step-by-step, deeply annotated exploration of every feature in the **ml-assert** library.\n",
    "We will cover:\n",
    "1. DataFrameAssertion (DFA) DSL\n",
    "2. Low-level distribution tests (KS, Chi-square, Wasserstein)\n",
    "3. High-level drift detection\n",
    "4. Model performance assertions\n",
    "5. Plugin system (file_exists, dvc_check)\n",
    "6. CLI execution and reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3d7a20",
   "metadata": {},
   "source": [
    "## What is DataFrameAssertion (DFA)?\n",
    "DataFrameAssertion provides a fluent, chainable API for asserting properties of pandas DataFrames,\n",
    "such as schema compliance (`schema`), absence of nulls (`no_nulls`), uniqueness (`unique`),\n",
    "value ranges (`in_range`), and membership in an allowed set (`values_in_set`).\n",
    "\n",
    "## What are Distribution Tests?\n",
    "ml-assert offers low-level statistical tests:\n",
    "- **Kolmogorov–Smirnov (KS)** for comparing numeric distributions\n",
    "- **Chi-squared** for comparing categorical distributions\n",
    "- **Wasserstein distance** for measuring distributional shift magnitude\n",
    "\n",
    "## What is Drift Detection?\n",
    "High-level drift detection (`assert_no_drift`) combines KS tests for numeric columns\n",
    "and Chi-squared tests for categorical columns. In our example, the first drift check is **expected to fail**\n",
    "because we deliberately shift the numeric mean and alter category proportions between the two datasets.\n",
    "\n",
    "## What are Model Performance Assertions?\n",
    "The `assert_model` DSL lets you chain checks on classification metrics:\n",
    "accuracy, precision, recall, F1, and ROC AUC—failing immediately if any metric is below its threshold.\n",
    "\n",
    "## What is the Plugin System?\n",
    "Plugins extend ml-assert via Python entry points. Built-in plugins include:\n",
    "- `file_exists`: verifies a file exists at a given path\n",
    "- `dvc_check`: ensures DVC-tracked files remain in sync with their metadata\n",
    "\n",
    "## CLI Usage\n",
    "The `ml_assert run config.yaml` command executes a series of assertions defined\n",
    "in a YAML file, generating both a machine-readable JSON report and a\n",
    "human-friendly HTML report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8d758c",
   "metadata": {},
   "source": [
    "## 1. DataFrameAssertion (DFA)\n",
    "The **DataFrameAssertion** DSL lets you chain checks about a pandas DataFrame:\n",
    "- Schema (columns + dtypes)\n",
    "- No nulls\n",
    "- Uniqueness\n",
    "- Value ranges\n",
    "- Values in a specific set\n",
    "\n",
    "If any check fails, an `AssertionError` is raised immediately, stopping execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aaff38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bcf0e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_assert import Assertion, schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47fe4903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a temporary artifacts directory\n",
    "artifact_dir = Path(\"ultimate_guide_artifacts\")\n",
    "artifact_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8b042f",
   "metadata": {},
   "source": [
    "### 1.1. Full DataFrame Validation (Expect Failure)\n",
    "We create a DataFrame with a column `empty_col` full of nulls.\n",
    "We then run a chain of DFA checks, including `no_nulls()` on **all** columns.\n",
    "Because `empty_col` contains 10 nulls, this should **fail** immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a113f5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample DataFrame:\n",
      "   user_id  age      city plan_type  monthly_spend  empty_col\n",
      "0      100   25  New York     basic             50        NaN\n",
      "1      101   30    London   premium            100        NaN\n",
      "2      102   22     Paris     basic             55        NaN\n",
      "3      103   45     Tokyo   premium            110        NaN\n",
      "4      104   30    London   premium            105        NaN\n",
      "5      105   50  New York     basic             45        NaN\n",
      "6      106   60    Sydney      free              0        NaN\n",
      "7      107   22     Paris      free              0        NaN\n",
      "8      108   33    London   premium            120        NaN\n",
      "9      109   41     Tokyo     basic             60        NaN\n"
     ]
    }
   ],
   "source": [
    "# Create sample DataFrame\n",
    "data = {\n",
    "    \"user_id\": list(range(100, 110)),\n",
    "    \"age\": [25, 30, 22, 45, 30, 50, 60, 22, 33, 41],\n",
    "    \"city\": [\n",
    "        \"New York\",\n",
    "        \"London\",\n",
    "        \"Paris\",\n",
    "        \"Tokyo\",\n",
    "        \"London\",\n",
    "        \"New York\",\n",
    "        \"Sydney\",\n",
    "        \"Paris\",\n",
    "        \"London\",\n",
    "        \"Tokyo\",\n",
    "    ],\n",
    "    \"plan_type\": [\n",
    "        \"basic\",\n",
    "        \"premium\",\n",
    "        \"basic\",\n",
    "        \"premium\",\n",
    "        \"premium\",\n",
    "        \"basic\",\n",
    "        \"free\",\n",
    "        \"free\",\n",
    "        \"premium\",\n",
    "        \"basic\",\n",
    "    ],\n",
    "    \"monthly_spend\": [50, 100, 55, 110, 105, 45, 0, 0, 120, 60],\n",
    "    \"empty_col\": [np.nan] * 10,\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Sample DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a167334a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running full DFA validation (this will fail):\n",
      "As expected, DFA failed: Column empty_col contains 10 null values\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRunning full DFA validation (this will fail):\")\n",
    "try:\n",
    "    s = schema()\n",
    "    s.col(\"user_id\").is_type(\"int64\").is_unique()\n",
    "    s.col(\"age\").is_type(\"int64\").in_range(18, 70)\n",
    "    s.col(\"city\").is_type(\"object\")\n",
    "\n",
    "    Assertion(df).satisfies(s).no_nulls().validate()\n",
    "    print(\"ERROR: DFA did not fail when it should have.\")\n",
    "except AssertionError as e:\n",
    "    print(f\"As expected, DFA failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016d3962",
   "metadata": {},
   "source": [
    "\n",
    "**Explanation:** The `no_nulls()` step checks **all** columns. Since `empty_col` has 10 null values, it raises an error listing that column and the count."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6619947e",
   "metadata": {},
   "source": [
    "### 1.2. Partial Column Validation (Expect Success)\n",
    "We can pass a list to `no_nulls()` to restrict the check to specific columns.\n",
    "Here we omit `empty_col`, so the validation should **pass**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2f8c2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running partial DFA validation (should succeed):\n",
      "Partial DFA validation passed.\n"
     ]
    }
   ],
   "source": [
    "print(\"Running partial DFA validation (should succeed):\")\n",
    "try:\n",
    "    Assertion(df).no_nulls(\n",
    "        [\"user_id\", \"age\", \"city\", \"plan_type\", \"monthly_spend\"]\n",
    "    ).validate()\n",
    "    print(\"Partial DFA validation passed.\")\n",
    "except AssertionError as e:\n",
    "    print(f\"ERROR: Partial DFA validation failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51100f27",
   "metadata": {},
   "source": [
    "**Explanation:** By specifying only the non-null columns, we bypass the failing `empty_col` check and the chain completes successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc22ebe",
   "metadata": {},
   "source": [
    "## 2. Low-level Distribution Tests\n",
    "ml-assert exposes individual distribution test functions for fine-grained control:\n",
    "- `assert_ks_test(sample1, sample2, alpha)`\n",
    "- `assert_chi2_test(observed, expected, alpha)`\n",
    "- `assert_wasserstein_distance(sample1, sample2, max_distance)`\n",
    "\n",
    "Each raises an `AssertionError` when the test condition is not met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06b6a7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_assert.stats.distribution import (\n",
    "    assert_chi2_test,\n",
    "    assert_ks_test,\n",
    "    assert_wasserstein_distance,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f7fd82",
   "metadata": {},
   "source": [
    "### 2.1. KS Test\n",
    "- **Pass case:** identical samples → no error\n",
    "- **Fail case:** sample shifted by +10 → p-value < alpha → error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef0a32dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS test pass (identical):\n",
      "  Passed.\n"
     ]
    }
   ],
   "source": [
    "arr1 = np.array([1, 2, 3, 4, 5])\n",
    "arr2 = arr1.copy()\n",
    "print(\"KS test pass (identical):\")\n",
    "try:\n",
    "    assert_ks_test(arr1, arr2, alpha=0.05)\n",
    "    print(\"  Passed.\")\n",
    "except AssertionError as e:\n",
    "    print(f\"  ERROR: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39971b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS test fail (shifted):\n",
      "  As expected: KS test failed (statistic=1.0000, p-value=0.0079 < 0.05)\n"
     ]
    }
   ],
   "source": [
    "arr3 = arr1 + 10\n",
    "print(\"KS test fail (shifted):\")\n",
    "try:\n",
    "    assert_ks_test(arr1, arr3, alpha=0.05)\n",
    "    print(\"  ERROR: Should have failed.\")\n",
    "except AssertionError as e:\n",
    "    print(f\"  As expected: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ac35d0",
   "metadata": {},
   "source": [
    "### 2.2. Chi-square Test\n",
    "- **Pass case:** observed == expected → no error\n",
    "- **Fail case:** reversed counts → p-value < alpha → error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c24cf9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square pass (same counts):\n",
      "  Passed.\n"
     ]
    }
   ],
   "source": [
    "obs = np.array([10, 20, 30])\n",
    "exp = obs.copy()\n",
    "print(\"Chi-square pass (same counts):\")\n",
    "try:\n",
    "    assert_chi2_test(obs, exp, alpha=0.05)\n",
    "    print(\"  Passed.\")\n",
    "except AssertionError as e:\n",
    "    print(f\"  ERROR: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce086179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square fail (reversed):\n",
      "  As expected: Chi-square test failed: p-value 2.6230937696693e-12 < alpha 0.05\n"
     ]
    }
   ],
   "source": [
    "exp2 = np.array([30, 20, 10])\n",
    "print(\"Chi-square fail (reversed):\")\n",
    "try:\n",
    "    assert_chi2_test(obs, exp2, alpha=0.05)\n",
    "    print(\"  ERROR: Should have failed.\")\n",
    "except AssertionError as e:\n",
    "    print(f\"  As expected: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df32acd1",
   "metadata": {},
   "source": [
    "### 2.3. Wasserstein Distance\n",
    "- **Pass case:** identical arrays → distance=0 ≤ max_distance → no error\n",
    "- **Fail case:** arrays differ by 10 units → exceeds max_distance → error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92a91616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wasserstein pass (identical):\n",
      "  Passed.\n"
     ]
    }
   ],
   "source": [
    "print(\"Wasserstein pass (identical):\")\n",
    "try:\n",
    "    assert_wasserstein_distance(arr1, arr2, max_distance=0.0)\n",
    "    print(\"  Passed.\")\n",
    "except AssertionError as e:\n",
    "    print(f\"  ERROR: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de8d4b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wasserstein fail (distance >1):\n",
      "  As expected: Wasserstein distance 10.0000 exceeds max 1.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"Wasserstein fail (distance >1):\")\n",
    "try:\n",
    "    assert_wasserstein_distance(arr1, arr3, max_distance=1.0)\n",
    "    print(\"  ERROR: Should have failed.\")\n",
    "except AssertionError as e:\n",
    "    print(f\"  As expected: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf31751f",
   "metadata": {},
   "source": [
    "## 3. High-level Drift Detection\n",
    "The `assert_no_drift(df1, df2, alpha)` function runs KS tests on numeric columns and Chi-square tests on categorical columns.\n",
    "It stops on the first failing column.\n",
    "\n",
    "**Failing example:** We deliberately shift the numeric mean from ~20 to ~30 and change city distribution\n",
    "(NY:50%→20%, SF:20%→50%), so drift is correctly detected in the first assertion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ca01c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from ml_assert.stats.drift import assert_no_drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0116cbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: N(20,5), balanced cities\n",
    "df_ref = pd.DataFrame(\n",
    "    {\n",
    "        \"temperature\": np.random.normal(20, 5, 500),\n",
    "        \"city\": np.random.choice([\"NY\", \"LA\", \"SF\"], 500, p=[0.5, 0.3, 0.2]),\n",
    "    }\n",
    ")\n",
    "# Drift: mean shifted +10, city distribution changed\n",
    "df_cur = pd.DataFrame(\n",
    "    {\n",
    "        \"temperature\": np.random.normal(30, 5, 500),\n",
    "        \"city\": np.random.choice([\"NY\", \"LA\", \"SF\"], 500, p=[0.2, 0.3, 0.5]),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2190718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drift case (expect failure):\n",
      "  As expected: KS test failed for series: p-value 0.0000 < alpha 0.05\n"
     ]
    }
   ],
   "source": [
    "print(\"Drift case (expect failure):\")\n",
    "try:\n",
    "    assert_no_drift(df_ref, df_cur, alpha=0.05)\n",
    "    print(\"  ERROR: Drift not detected.\")\n",
    "except AssertionError as e:\n",
    "    print(f\"  As expected: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90dc7a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No-drift case (expect success):\n",
      "  Passed.\n"
     ]
    }
   ],
   "source": [
    "# No drift: identical data\n",
    "print(\"No-drift case (expect success):\")\n",
    "df_cur2 = df_ref.copy()\n",
    "try:\n",
    "    assert_no_drift(df_ref, df_cur2, alpha=0.05)\n",
    "    print(\"  Passed.\")\n",
    "except AssertionError as e:\n",
    "    print(f\"  ERROR: False positive: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e7562c",
   "metadata": {},
   "source": [
    "## 4. Model Performance Assertions\n",
    "The `assert_model(y_true, y_pred, y_scores)` DSL lets you chain checks on:\n",
    "accuracy, precision, recall, F1, ROC AUC.\n",
    "It raises on the first metric below its threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cbfc813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ml_assert import assert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f581b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Titanic data\n",
    "titanic = sns.load_dataset(\"titanic\")\n",
    "titanic[\"age\"] = titanic[\"age\"].fillna(titanic[\"age\"].median())\n",
    "titanic.drop([\"deck\", \"embark_town\", \"alive\"], axis=1, inplace=True)\n",
    "titanic = pd.get_dummies(\n",
    "    titanic,\n",
    "    columns=[\"sex\", \"class\", \"who\", \"adult_male\", \"alone\", \"embarked\"],\n",
    "    drop_first=True,\n",
    ")\n",
    "X = titanic.drop(\"survived\", axis=1)\n",
    "y = titanic[\"survived\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "model = LogisticRegression(max_iter=1000, random_state=42).fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_scores = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9e5c8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model assertions (thresholds should be met):\n",
      "  All metrics passed.\n"
     ]
    }
   ],
   "source": [
    "print(\"Running model assertions (thresholds should be met):\")\n",
    "try:\n",
    "    # Create model assertion\n",
    "    model_assertion = assert_model(y_test, y_pred)\n",
    "\n",
    "    # Chain metric assertions with their thresholds\n",
    "    model_assertion.accuracy(min_score=0.75).precision(min_score=0.65).recall(\n",
    "        min_score=0.60\n",
    "    ).f1(min_score=0.70).validate()\n",
    "    print(\"  All metrics passed.\")\n",
    "except AssertionError as e:\n",
    "    print(f\"  ERROR: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63638077",
   "metadata": {},
   "source": [
    "**Explanation:** If any metric fell below its threshold, an `AssertionError` would be raised at that metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52143c42",
   "metadata": {},
   "source": [
    "## 5. Plugin System\n",
    "We ship two plugins by default:\n",
    "1. **file_exists**: check that a file exists.\n",
    "2. **dvc_check**: check that a DVC-tracked file is in sync."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8498a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_exists plugin: Created ultimate_guide_artifacts/my_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# file_exists demo\n",
    "file_exists_path = artifact_dir / \"my_model.pkl\"\n",
    "file_exists_path.touch()\n",
    "print(f\"file_exists plugin: Created {file_exists_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab754052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized DVC repository.\n",
      "\n",
      "+---------------------------------------------------------------------+\n",
      "|                                                                     |\n",
      "|        DVC has enabled anonymous aggregate usage analytics.         |\n",
      "|     Read the analytics documentation (and how to opt-out) here:     |\n",
      "|             <https://dvc.org/doc/user-guide/analytics>              |\n",
      "|                                                                     |\n",
      "+---------------------------------------------------------------------+\n",
      "\n",
      "What's next?\n",
      "------------\n",
      "- Check out the documentation: <https://dvc.org/doc>\n",
      "- Get help and share ideas: <https://dvc.org/chat>\n",
      "- Star us on GitHub: <https://github.com/iterative/dvc>\n",
      "dvc_check plugin: DVC setup and added file_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?25l⠋ Checking graph\n",
      "\u001b[?25h\r"
     ]
    }
   ],
   "source": [
    "# dvc_check demo\n",
    "import subprocess\n",
    "\n",
    "dvc_data = artifact_dir / \"model_data.csv\"\n",
    "dvc_data.write_text(\"a,b\\n1,2\")\n",
    "if not (artifact_dir / \".dvc\").exists():\n",
    "    subprocess.run([\"dvc\", \"init\", \"--no-scm\"], cwd=artifact_dir, check=True)\n",
    "    subprocess.run([\"dvc\", \"add\", dvc_data.name], cwd=artifact_dir, check=True)\n",
    "    print(\"dvc_check plugin: DVC setup and added file_data.csv\")\n",
    "else:\n",
    "    print(\"dvc_check plugin: DVC already initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc6e289",
   "metadata": {},
   "source": [
    "## 6. CLI: End-to-End Run\n",
    "We can run all steps via a YAML config and the `ml_assert run` command.\n",
    "This produces a JSON and HTML report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc4fc093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote config.yaml and artifact CSVs in: /Users/shinde/Documents/Projects/ml-assert/examples/ultimate_guide_artifacts\n"
     ]
    }
   ],
   "source": [
    "# CLI: Save artifacts and run inside artifacts directory\n",
    "import yaml\n",
    "\n",
    "# Change into artifact_dir so CSVs and config go there\n",
    "old_cwd = os.getcwd()\n",
    "os.chdir(artifact_dir)\n",
    "# Write CSV artifacts for CLI\n",
    "df_ref.to_csv(\"ref.csv\", index=False)\n",
    "df_cur.to_csv(\"cur.csv\", index=False)\n",
    "pd.Series(y_test).to_csv(\"y_true.csv\", index=False, header=False)\n",
    "pd.Series(y_pred).to_csv(\"y_pred.csv\", index=False, header=False)\n",
    "pd.Series(y_scores).to_csv(\"y_scores.csv\", index=False, header=False)\n",
    "# Create config.yaml referencing local files\n",
    "config = {\n",
    "    \"steps\": [\n",
    "        {\"type\": \"drift\", \"train\": \"ref.csv\", \"test\": \"cur.csv\", \"alpha\": 0.05},\n",
    "        {\n",
    "            \"type\": \"model_performance\",\n",
    "            \"y_true\": \"y_true.csv\",\n",
    "            \"y_pred\": \"y_pred.csv\",\n",
    "            \"y_scores\": \"y_scores.csv\",\n",
    "            \"assertions\": {\"accuracy\": 0.75},\n",
    "        },\n",
    "        {\"type\": \"file_exists\", \"path\": \"my_model.pkl\"},\n",
    "        {\"type\": \"dvc_check\", \"path\": \"model_data.csv\"},\n",
    "    ]\n",
    "}\n",
    "with open(\"config.yaml\", \"w\") as f:\n",
    "    yaml.dump(config, f)\n",
    "print(\"Wrote config.yaml and artifact CSVs in:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f9155e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: ml_assert run config.yaml\n",
      "CLI exit code: 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Command not found: ml_assert\n"
     ]
    }
   ],
   "source": [
    "# Run the CLI\n",
    "print(\"Running: ml_assert run config.yaml\")\n",
    "exit_code = os.system(\"poetry run ml_assert run config.yaml\")\n",
    "print(f\"CLI exit code: {exit_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "473f5f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return to original directory\n",
    "os.chdir(old_cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3d2056",
   "metadata": {},
   "source": [
    "**Inspect the generated reports**:\n",
    "- `ultimate_guide_artifacts/config.report.json`\n",
    "- `ultimate_guide_artifacts/config.report.html`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d05500",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "You now have a detailed, cell-by-cell guide illustrating exactly how ml-assert works,\n",
    "with both passing and failing examples, and end-to-end automation via the CLI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-assert-8o_lYmPL-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
